{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-19T11:54:13.892801Z","iopub.status.busy":"2024-02-19T11:54:13.892033Z","iopub.status.idle":"2024-02-19T11:54:17.524787Z","shell.execute_reply":"2024-02-19T11:54:17.523783Z","shell.execute_reply.started":"2024-02-19T11:54:13.892772Z"},"trusted":true},"outputs":[],"source":["import copy\n","from pathlib import Path\n","import random\n","from statistics import mean\n","import numpy as np\n","import torch\n","from torch import nn\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:54:21.197461Z","iopub.status.busy":"2024-02-19T11:54:21.196476Z","iopub.status.idle":"2024-02-19T11:54:34.948544Z","shell.execute_reply":"2024-02-19T11:54:34.947346Z","shell.execute_reply.started":"2024-02-19T11:54:21.197405Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting easyfsl\n","  Downloading easyfsl-1.5.0-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (3.7.4)\n","Requirement already satisfied: pandas>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (2.1.4)\n","Requirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (2.1.2)\n","Requirement already satisfied: torchvision>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (0.16.2)\n","Requirement already satisfied: tqdm>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from easyfsl) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (1.4.5)\n","Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (1.24.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (21.3)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.0->easyfsl) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->easyfsl) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.5.0->easyfsl) (2023.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->easyfsl) (2023.12.2)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.7.0->easyfsl) (2.31.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->easyfsl) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.5.0->easyfsl) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.7.0->easyfsl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.7.0->easyfsl) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.7.0->easyfsl) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.7.0->easyfsl) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.5.0->easyfsl) (1.3.0)\n","Downloading easyfsl-1.5.0-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.8/72.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: easyfsl\n","Successfully installed easyfsl-1.5.0\n"]}],"source":["!pip install easyfsl"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:54:38.368511Z","iopub.status.busy":"2024-02-19T11:54:38.367650Z","iopub.status.idle":"2024-02-19T11:54:41.885312Z","shell.execute_reply":"2024-02-19T11:54:41.884526Z","shell.execute_reply.started":"2024-02-19T11:54:38.368476Z"},"trusted":true},"outputs":[],"source":["from easyfsl.samplers import TaskSampler\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import random_split"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:54:44.765421Z","iopub.status.busy":"2024-02-19T11:54:44.764439Z","iopub.status.idle":"2024-02-19T11:54:44.773518Z","shell.execute_reply":"2024-02-19T11:54:44.772519Z","shell.execute_reply.started":"2024-02-19T11:54:44.765387Z"},"trusted":true},"outputs":[],"source":["random_seed = 0\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","random.seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:54:47.523460Z","iopub.status.busy":"2024-02-19T11:54:47.522457Z","iopub.status.idle":"2024-02-19T11:54:47.527731Z","shell.execute_reply":"2024-02-19T11:54:47.526802Z","shell.execute_reply.started":"2024-02-19T11:54:47.523429Z"},"trusted":true},"outputs":[],"source":["n_way = 5\n","n_shot = 5\n","n_query = 10\n","\n","DEVICE = \"cuda\"\n","n_workers = 12\n","n_tasks_per_epoch = 500\n","n_validation_tasks = 100"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:54:50.163882Z","iopub.status.busy":"2024-02-19T11:54:50.163284Z","iopub.status.idle":"2024-02-19T11:54:50.168929Z","shell.execute_reply":"2024-02-19T11:54:50.167960Z","shell.execute_reply.started":"2024-02-19T11:54:50.163850Z"},"trusted":true},"outputs":[],"source":["train_transform = transforms.Compose([\n","    \n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.RandomRotation(degrees=45),\n","    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),  \n","    transforms.ToTensor(),\n","    \n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:54:52.840641Z","iopub.status.busy":"2024-02-19T11:54:52.839837Z","iopub.status.idle":"2024-02-19T11:55:03.962348Z","shell.execute_reply":"2024-02-19T11:55:03.961280Z","shell.execute_reply.started":"2024-02-19T11:54:52.840611Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["test_data_path = \"/kaggle/input/bm-dataset/BM_Test\"\n","val_data_path = \"/kaggle/input/bm-dataset/BM_Val\"\n","final_data_path = \"/kaggle/input/bm-dataset/BM_Final\"\n","val_set = ImageFolder(root=val_data_path, transform=test_transform)\n","val_set.get_labels = lambda: [instance[1] for instance in val_set]\n","val_sampler = TaskSampler(\n","    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks\n",")\n","val_loader = DataLoader(\n","    val_set,\n","    batch_sampler=val_sampler,\n","    num_workers=n_workers,\n","    pin_memory=True,\n","    collate_fn=val_sampler.episodic_collate_fn,\n",")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:55:07.244752Z","iopub.status.busy":"2024-02-19T11:55:07.244393Z","iopub.status.idle":"2024-02-19T11:55:07.267389Z","shell.execute_reply":"2024-02-19T11:55:07.266499Z","shell.execute_reply.started":"2024-02-19T11:55:07.244724Z"},"trusted":true},"outputs":[],"source":["from abc import abstractmethod\n","from typing import Optional\n","import torch\n","from torch import Tensor, nn\n","from easyfsl.methods.utils import compute_prototypes\n","\n","class MetaClassifier(nn.Module):\n","\n","    def __init__(\n","        self,\n","        backbone: Optional[nn.Module] = None,\n","        use_softmax: bool = False,\n","        feature_centering: Optional[Tensor] = None,\n","        feature_normalization: Optional[float] = None,\n","        \n","    ):\n","        \n","        super().__init__()\n","\n","        self.backbone = backbone if backbone is not None else nn.Identity()\n","        self.use_softmax = use_softmax\n","\n","        self.prototypes = torch.tensor(())\n","        self.support_features = torch.tensor(())\n","        self.support_labels = torch.tensor(())\n","\n","        self.feature_centering = (\n","            feature_centering if feature_centering is not None else torch.tensor(0)\n","        )\n","        self.feature_normalization = feature_normalization\n","\n","    @abstractmethod\n","    def forward(\n","        self,\n","        query_images: Tensor,\n","    ) -> Tensor:\n","       \n","        raise NotImplementedError(\n","            \n","        )\n","    def compute_prototypes(support_features: Tensor, support_labels: Tensor) -> Tensor:\n","    \n","\n","        n_way = len(torch.unique(support_labels))\n","    \n","        return torch.cat(\n","            [\n","                support_features[torch.nonzero(support_labels == label)].mean(0)\n","                for label in range(n_way)\n","            ]\n","        )\n","\n","    def process_support_set(\n","        self,\n","        support_images: Tensor,\n","        support_labels: Tensor,\n","    ):\n","        \n","        self.compute_prototypes_and_store_support_set(support_images, support_labels)\n","\n","    @staticmethod\n","    def is_transductive() -> bool:\n","        raise NotImplementedError(\n","            \"All few-shot algorithms must implement a is_transductive method.\"\n","        )\n","    def compute_prototypes_and_store_support_set(\n","        self,\n","        support_images: Tensor,\n","        support_labels: Tensor,\n","    ):\n","        self.support_labels = support_labels\n","        self.support_features = self.compute_features(support_images)\n","        self._raise_error_if_features_are_multi_dimensional(self.support_features)\n","        self.prototypes = compute_prototypes(self.support_features, support_labels)\n","    def compute_features(self, images: Tensor) -> Tensor:\n","        \n","        original_features = self.backbone(images)\n","        centered_features = original_features - self.feature_centering\n","        if self.feature_normalization is not None:\n","            return nn.functional.normalize(\n","                centered_features, p=self.feature_normalization, dim=1\n","            )\n","        return centered_features\n","    \n","    def softmax_if_specified(self, output: Tensor, temperature: float = 1.0) -> Tensor:\n","        \n","        return (temperature * output).softmax(-1) if self.use_softmax else output\n","    def l2_distance_to_prototypes(self, samples: Tensor) -> Tensor:\n","        \n","        return -torch.cdist(samples, self.prototypes)\n","    @staticmethod\n","    def _raise_error_if_features_are_multi_dimensional(features: Tensor):\n","        if len(features.shape) != 2:\n","            raise ValueError(\n","                \"Illegal backbone or feature shape. \"\n","                \"Expected output for an image is a 1-dim tensor.\"\n","            )\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:55:10.459360Z","iopub.status.busy":"2024-02-19T11:55:10.458996Z","iopub.status.idle":"2024-02-19T11:55:10.467187Z","shell.execute_reply":"2024-02-19T11:55:10.466206Z","shell.execute_reply.started":"2024-02-19T11:55:10.459333Z"},"trusted":true},"outputs":[],"source":["class PrototypicalNetworks(MetaClassifier):\n","    def __init__(\n","        self,\n","        backbone: Optional[nn.Module] = None,\n","        use_softmax: bool = False,\n","        feature_centering: Optional[Tensor] = None,\n","        feature_normalization: Optional[float] = None,\n","    ):\n","        super().__init__(backbone, use_softmax, feature_centering, feature_normalization)\n","        self.train_loader = None  # Initialize train_loader attribute\n","\n","    def forward(self, query_images: Tensor) -> Tensor:\n","        query_features = self.compute_features(query_images)\n","        self._raise_error_if_features_are_multi_dimensional(query_features)\n","        scores = self.l2_distance_to_prototypes(query_features)\n","        return self.softmax_if_specified(scores)\n","\n","    @staticmethod\n","    def is_transductive() -> bool:\n","        return False\n","\n","    def get_data_loader(self):\n","        return self.train_loader\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:55:14.521786Z","iopub.status.busy":"2024-02-19T11:55:14.521412Z","iopub.status.idle":"2024-02-19T11:55:14.530552Z","shell.execute_reply":"2024-02-19T11:55:14.529264Z","shell.execute_reply.started":"2024-02-19T11:55:14.521755Z"},"trusted":true},"outputs":[],"source":["from torch.optim import SGD, Optimizer\n","def training_epoch(\n","    model: MetaClassifier, data_loader: DataLoader, optimizer: Optimizer\n","):\n","    all_loss = []\n","    model.train()\n","    with tqdm(\n","        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n","    ) as tqdm_train:\n","        for episode_index, (\n","            support_images,\n","            support_labels,\n","            query_images,\n","            query_labels,\n","            _,\n","        ) in tqdm_train:\n","            optimizer.zero_grad()\n","            model.process_support_set(\n","                support_images.to(DEVICE), support_labels.to(DEVICE)\n","            )\n","            classification_scores = model(query_images.to(DEVICE))\n","\n","            loss = LOSS_FUNCTION(classification_scores, query_labels.to(DEVICE))\n","            loss.backward()\n","            optimizer.step()\n","            all_loss.append(loss.item())\n","\n","            tqdm_train.set_postfix(loss=mean(all_loss))\n","\n","    return mean(all_loss)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:55:19.045727Z","iopub.status.busy":"2024-02-19T11:55:19.045068Z","iopub.status.idle":"2024-02-19T11:55:19.700737Z","shell.execute_reply":"2024-02-19T11:55:19.699763Z","shell.execute_reply.started":"2024-02-19T11:55:19.045698Z"},"trusted":true},"outputs":[],"source":["from typing import List, Optional, Tuple\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","def evaluate_on_one_task(\n","    model: FewShotClassifier,\n","    support_images: Tensor,\n","    support_labels: Tensor,\n","    query_images: Tensor,\n","    query_labels: Tensor,\n",") -> Tuple[int, int]:\n","    \n","    model.process_support_set(support_images, support_labels)\n","    predictions = model(query_images).detach().data\n","    number_of_correct_predictions = int(\n","        (torch.max(predictions, 1)[1] == query_labels).sum().item()\n","    )\n","    return number_of_correct_predictions, len(query_labels)\n","def evaluate(\n","    model: FewShotClassifier,\n","    data_loader: DataLoader,\n","    device: str = \"cuda\",\n","    use_tqdm: bool = True,\n","    tqdm_prefix: Optional[str] = None,\n",") -> Tuple[float, float, float, float]:\n","    total_predictions = 0\n","    correct_predictions = 0\n","    all_predictions = []\n","    all_targets = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        with tqdm(\n","            enumerate(data_loader),\n","            total=len(data_loader),\n","            disable=not use_tqdm,\n","            desc=tqdm_prefix,\n","        ) as tqdm_eval:\n","            for _, (\n","                support_images,\n","                support_labels,\n","                query_images,\n","                query_labels,\n","                _,\n","            ) in tqdm_eval:\n","                correct, total = evaluate_on_one_task(\n","                    model,\n","                    support_images.to(device),\n","                    support_labels.to(device),\n","                    query_images.to(device),\n","                    query_labels.to(device),\n","                )\n","\n","                total_predictions += total\n","                correct_predictions += correct\n","\n","                all_predictions.extend(model(query_images).detach().cpu().numpy().argmax(axis=1))\n","                all_targets.extend(query_labels.cpu().numpy())\n","\n","                tqdm_eval.set_postfix(accuracy=correct_predictions / total_predictions)\n","\n","    accuracy = correct_predictions / total_predictions\n","    precision = precision_score(all_targets, all_predictions, average='weighted')\n","    recall = recall_score(all_targets, all_predictions, average='weighted')\n","    f1 = f1_score(all_targets, all_predictions, average='weighted')\n","\n","    return accuracy, precision, recall, f1"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:55:28.221405Z","iopub.status.busy":"2024-02-19T11:55:28.220456Z","iopub.status.idle":"2024-02-19T11:55:28.229225Z","shell.execute_reply":"2024-02-19T11:55:28.228305Z","shell.execute_reply.started":"2024-02-19T11:55:28.221371Z"},"trusted":true},"outputs":[],"source":["def create_clients(train_paths, few_shot_classifier, transform, n_way, n_shot, n_query, n_tasks_per_epoch, n_workers, optimizer, loss_function):\n","    clients = []\n","    for i, path in enumerate(train_paths):\n","        client_name = 'client_' + str(i)\n","        \n","        # Load data\n","        train_set = ImageFolder(root=path, transform=transform)\n","        train_set.get_labels = lambda: [instance[1] for instance in train_set]\n","        \n","        # Define the task sampler\n","        train_sampler = TaskSampler(train_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_tasks_per_epoch)\n","        \n","        # Create DataLoader with the task sampler\n","        train_loader = DataLoader(\n","            train_set,\n","            batch_sampler=train_sampler,\n","            num_workers=n_workers,\n","            pin_memory=True,\n","            collate_fn=train_sampler.episodic_collate_fn,\n","        )\n","        \n","        \n","        few_shot_classifier.train_loader = train_loader\n","        \n","        clients.append((client_name, few_shot_classifier))\n","    \n","    return clients\n","\n","# Define your paths for different subsets of data\n","train_data_paths = [\"/kaggle/input/bm-train/BM_Train1\",\n","                    \"/kaggle/input/bm-train/BM_Train2\",\n","                    \"/kaggle/input/bm-train/BM_Train3\",\n","                    \"/kaggle/input/bm-train/BM_Train4\"]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:55:31.249402Z","iopub.status.busy":"2024-02-19T11:55:31.248745Z","iopub.status.idle":"2024-02-19T11:55:32.226351Z","shell.execute_reply":"2024-02-19T11:55:32.225335Z","shell.execute_reply.started":"2024-02-19T11:55:31.249359Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 118MB/s] \n"]}],"source":["from torchvision.models import resnet18\n","\n","convolutional_network = resnet18(pretrained=True)\n","convolutional_network.fc = nn.Flatten()\n","convolutional_network = nn.DataParallel(convolutional_network)\n","#print(convolutional_network)\n","meta_classifier = PrototypicalNetworks(convolutional_network).to(DEVICE)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:55:36.094978Z","iopub.status.busy":"2024-02-19T11:55:36.094119Z","iopub.status.idle":"2024-02-19T11:55:36.101433Z","shell.execute_reply":"2024-02-19T11:55:36.100482Z","shell.execute_reply.started":"2024-02-19T11:55:36.094944Z"},"trusted":true},"outputs":[],"source":["\n","from torch.optim.lr_scheduler import MultiStepLR\n","\n","\n","\n","LOSS_FUNCTION = nn.CrossEntropyLoss()\n","\n","n_epochs = 1\n","scheduler_milestones = [120, 160]\n","scheduler_gamma = 0.1\n","learning_rate = 1e-2\n","\n","\n","train_optimizer = SGD(\n","    few_shot_classifier.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n",")\n","train_scheduler = MultiStepLR(\n","    train_optimizer,\n","    milestones=scheduler_milestones,\n","    gamma=scheduler_gamma,\n",")\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:55:39.137438Z","iopub.status.busy":"2024-02-19T11:55:39.136809Z","iopub.status.idle":"2024-02-19T11:56:33.107145Z","shell.execute_reply":"2024-02-19T11:56:33.106247Z","shell.execute_reply.started":"2024-02-19T11:55:39.137408Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["clients = create_clients(train_data_paths, few_shot_classifier, train_transform, n_way, n_shot, n_query, n_tasks_per_epoch, n_workers, train_optimizer, LOSS_FUNCTION)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T11:56:36.596243Z","iopub.status.busy":"2024-02-19T11:56:36.595863Z","iopub.status.idle":"2024-02-19T12:22:44.671243Z","shell.execute_reply":"2024-02-19T12:22:44.670172Z","shell.execute_reply.started":"2024-02-19T11:56:36.596215Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Round 1/3\n","Training client_0\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 500/500 [02:09<00:00,  3.87it/s, loss=0.474]"]},{"name":"stdout","output_type":"stream","text":["Training client_1\n"]},{"name":"stderr","output_type":"stream","text":["\n","Training: 100%|██████████| 500/500 [02:04<00:00,  4.00it/s, loss=0.0897]"]},{"name":"stdout","output_type":"stream","text":["Training client_2\n"]},{"name":"stderr","output_type":"stream","text":["\n","Training: 100%|██████████| 500/500 [02:05<00:00,  3.98it/s, loss=0.0226]"]},{"name":"stdout","output_type":"stream","text":["Training client_3\n"]},{"name":"stderr","output_type":"stream","text":["\n","Training: 100%|██████████| 500/500 [02:04<00:00,  4.01it/s, loss=0.00937]\n","Validation: 100%|██████████| 100/100 [00:19<00:00,  5.02it/s, accuracy=0.706]\n"]},{"name":"stdout","output_type":"stream","text":["New best model saved!\n","Round 2/3\n","Training client_0\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 500/500 [02:05<00:00,  3.99it/s, loss=0.0136]"]},{"name":"stdout","output_type":"stream","text":["Training client_1\n"]},{"name":"stderr","output_type":"stream","text":["\n","Training: 100%|██████████| 500/500 [02:04<00:00,  4.01it/s, loss=0.00639]"]},{"name":"stdout","output_type":"stream","text":["Training client_2\n"]},{"name":"stderr","output_type":"stream","text":["\n","Training: 100%|██████████| 500/500 [02:04<00:00,  4.01it/s, loss=0.0036] "]},{"name":"stdout","output_type":"stream","text":["Training client_3\n"]},{"name":"stderr","output_type":"stream","text":["\n","Training: 100%|██████████| 500/500 [02:04<00:00,  4.02it/s, loss=0.00191]\n","Validation: 100%|██████████| 100/100 [00:19<00:00,  5.06it/s, accuracy=0.677]"]},{"name":"stdout","output_type":"stream","text":["Round 3/3\n","Training client_0\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 500/500 [02:04<00:00,  4.02it/s, loss=0.00195]"]},{"name":"stdout","output_type":"stream","text":["Training client_1\n"]},{"name":"stderr","output_type":"stream","text":["\n","Training: 100%|██████████| 500/500 [02:04<00:00,  4.01it/s, loss=0.00182]"]},{"name":"stdout","output_type":"stream","text":["Training client_2\n"]},{"name":"stderr","output_type":"stream","text":["\n","Training: 100%|██████████| 500/500 [02:04<00:00,  4.01it/s, loss=0.00201]"]},{"name":"stdout","output_type":"stream","text":["Training client_3\n"]},{"name":"stderr","output_type":"stream","text":["\n","Training: 100%|██████████| 500/500 [02:04<00:00,  4.00it/s, loss=0.0011] \n","Validation: 100%|██████████| 100/100 [00:19<00:00,  5.05it/s, accuracy=0.657]\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["n_rounds = 3\n","n_epochs_per_round = 1\n","best_validation_accuracy = 0.0\n","best_state = None\n","\n","for round in range(n_rounds):\n","    print(f\"Round {round + 1}/{n_rounds}\")\n","    \n","    \n","    client_weights = {}\n","    for client_name, client_model in clients:\n","        print(f\"Training {client_name}\")\n","        \n","        \n","        client_model = PrototypicalNetworks(convolutional_network).to(DEVICE)\n","        client_model.train_loader = meta_classifier.train_loader  \n","        \n","        train_loader = client_model.train_loader\n","        for _ in range(n_epochs_per_round):\n","            average_loss = training_epoch(client_model, train_loader, train_optimizer)\n","        \n","        client_weights[client_name] = copy.deepcopy(client_model.state_dict())\n","\n","    \n","    weighted_average_weights = {}\n","    total_clients = len(clients)\n","    for name, weights in client_weights.items():\n","        for param_name, param in weights.items():\n","            if name == 'client_0': \n","                weighted_average_weights[param_name] = param / total_clients\n","            else:\n","                weighted_average_weights[param_name] += param / total_clients\n","\n","    meta_classifier.load_state_dict(weighted_average_weights)\n","\n","    # Evaluate the updated central model on the validation set\n","    validation_accuracy, precision, recall, f1 = evaluate(few_shot_classifier, val_loader, DEVICE, tqdm_prefix=\"Validation\")\n","\n","    # Save the best model if validation accuracy improves\n","    if validation_accuracy > best_validation_accuracy:\n","        best_validation_accuracy = validation_accuracy\n","        best_state = copy.deepcopy(few_shot_classifier.state_dict())\n","        torch.save(best_state, \"best_model.pth\")\n","        print(\"New best model saved!\")\n","\n","    # Step the scheduler\n","    train_scheduler.step()\n","\n","# Load the best model state\n","few_shot_classifier.load_state_dict(best_state)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import copy\n","\n","n_rounds = 3\n","n_epochs_per_round = 1\n","best_validation_accuracy = 0.0\n","best_state = None\n","\n","\n","few_shot_classifier = PrototypicalNetworks(convolutional_network).to(DEVICE)\n","\n","for round in range(n_rounds):\n","    print(f\"Round {round + 1}/{n_rounds}\")\n","    \n","    # Train each client individually for one epoch on the current global model\n","    client_weights = {}\n","    for client_name, client_model in clients:\n","        print(f\"Training {client_name} on global model\")\n","        \n","        \n","        client_model.load_state_dict(copy.deepcopy(few_shot_classifier.state_dict()))\n","        \n","        # Train the client model for one epoch\n","        for _ in range(n_epochs_per_round):\n","            average_loss = training_epoch(client_model, client_model.train_loader, train_optimizer)\n","        \n","        # Save the trained weights of the client model\n","        client_weights[client_name] = copy.deepcopy(client_model.state_dict())\n","\n","    # Perform weighted averaging of the weights\n","    weighted_average_weights = {}\n","    total_clients = len(clients)\n","    for name, weights in client_weights.items():\n","        for param_name, param in weights.items():\n","            if name == 'client_0':  # For the first client, initialize the weighted average weights\n","                weighted_average_weights[param_name] = param / total_clients\n","            else:\n","                weighted_average_weights[param_name] += param / total_clients\n","\n","    # Update the global model with the weighted average weights\n","    few_shot_classifier.load_state_dict(weighted_average_weights)\n","\n","    # Evaluate the updated global model on the validation set\n","    validation_accuracy, precision, recall, f1 = evaluate(few_shot_classifier, val_loader, DEVICE, tqdm_prefix=\"Validation\")\n","\n","    # Save the best model if validation accuracy improves\n","    if validation_accuracy > best_validation_accuracy:\n","        best_validation_accuracy = validation_accuracy\n","        best_state = copy.deepcopy(few_shot_classifier.state_dict())\n","        torch.save(best_state, \"best_model.pth\")\n","        print(\"New best model saved!\")\n","\n","    # Step the scheduler\n","    train_scheduler.step()\n","\n","# Load the best model state\n","few_shot_classifier.load_state_dict(best_state)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-19T12:28:57.652100Z","iopub.status.idle":"2024-02-19T12:28:57.652460Z","shell.execute_reply":"2024-02-19T12:28:57.652294Z","shell.execute_reply.started":"2024-02-19T12:28:57.652280Z"},"trusted":true},"outputs":[],"source":["best_state = torch.load(\"best_model.pth\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T12:22:44.737569Z","iopub.status.busy":"2024-02-19T12:22:44.737226Z","iopub.status.idle":"2024-02-19T12:22:44.742434Z","shell.execute_reply":"2024-02-19T12:22:44.741534Z","shell.execute_reply.started":"2024-02-19T12:22:44.737537Z"},"trusted":true},"outputs":[],"source":["n_way = 3\n","n_shot = 3\n","n_query = 7"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T12:22:44.745575Z","iopub.status.busy":"2024-02-19T12:22:44.744885Z","iopub.status.idle":"2024-02-19T12:22:44.799652Z","shell.execute_reply":"2024-02-19T12:22:44.798945Z","shell.execute_reply.started":"2024-02-19T12:22:44.745548Z"},"trusted":true},"outputs":[],"source":["n_tasks_per_epoch = 10\n","n_validation_tasks = 100\n","n_test_tasks = 100\n","n_epochs = 20\n","test_set = ImageFolder(root=test_data_path, transform=train_transform)\n","final_set = ImageFolder(root=final_data_path, transform=test_transform)\n","test_set.get_labels = lambda: [instance[1] for instance in test_set]\n","final_set.get_labels = lambda: [instance[1] for instance in final_set]\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T12:22:44.801067Z","iopub.status.busy":"2024-02-19T12:22:44.800732Z","iopub.status.idle":"2024-02-19T12:22:45.586774Z","shell.execute_reply":"2024-02-19T12:22:45.585762Z","shell.execute_reply.started":"2024-02-19T12:22:44.801035Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["test_sampler = TaskSampler(\n","    test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_tasks_per_epoch\n",")\n","final_sampler = TaskSampler(\n","    final_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks\n",")\n","test_loader = DataLoader(\n","    test_set,\n","    batch_sampler=test_sampler,\n","    num_workers=n_workers,\n","    pin_memory=True,\n","    collate_fn=test_sampler.episodic_collate_fn,\n",")\n","final_loader = DataLoader(\n","    final_set,\n","    batch_sampler=final_sampler,\n","    num_workers=n_workers,\n","    pin_memory=True,\n","    collate_fn=final_sampler.episodic_collate_fn,\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T12:22:45.588361Z","iopub.status.busy":"2024-02-19T12:22:45.588037Z","iopub.status.idle":"2024-02-19T12:22:45.831782Z","shell.execute_reply":"2024-02-19T12:22:45.830895Z","shell.execute_reply.started":"2024-02-19T12:22:45.588335Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["new_model = resnet18(weights=None).to(DEVICE)\n","new_model.fc = nn.Flatten()\n","new_model = nn.DataParallel(new_model)\n","#print(new_model)\n","new_model = PrototypicalNetworks(convolutional_network).to(DEVICE)\n","new_model.load_state_dict(best_state)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T12:22:45.833542Z","iopub.status.busy":"2024-02-19T12:22:45.833269Z","iopub.status.idle":"2024-02-19T12:22:45.839193Z","shell.execute_reply":"2024-02-19T12:22:45.838104Z","shell.execute_reply.started":"2024-02-19T12:22:45.833519Z"},"trusted":true},"outputs":[],"source":["test_optimizer = SGD(\n","    new_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n",")\n","test_scheduler = MultiStepLR(\n","    test_optimizer,\n","    milestones=scheduler_milestones,\n","    gamma=scheduler_gamma,\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T12:22:45.840721Z","iopub.status.busy":"2024-02-19T12:22:45.840450Z","iopub.status.idle":"2024-02-19T12:28:41.928458Z","shell.execute_reply":"2024-02-19T12:28:41.927348Z","shell.execute_reply.started":"2024-02-19T12:22:45.840692Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 10/10 [00:02<00:00,  4.39it/s, loss=0.512]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.92it/s, accuracy=0.946]\n"]},{"name":"stdout","output_type":"stream","text":["new best model!\n","Epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.57it/s, loss=0.361]\n","Validation: 100%|██████████| 100/100 [00:15<00:00,  6.56it/s, accuracy=0.872]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.70it/s, loss=0.281]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.80it/s, accuracy=0.919]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.63it/s, loss=0.19] \n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.68it/s, accuracy=0.973]\n"]},{"name":"stdout","output_type":"stream","text":["new best model!\n","Epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.56it/s, loss=0.213]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.80it/s, accuracy=0.902]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s, loss=0.142]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.68it/s, accuracy=0.926]"]},{"name":"stdout","output_type":"stream","text":["Epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.67it/s, loss=0.173]\n","Validation: 100%|██████████| 100/100 [00:15<00:00,  6.64it/s, accuracy=0.878]"]},{"name":"stdout","output_type":"stream","text":["Epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.65it/s, loss=0.0894]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.82it/s, accuracy=0.964]"]},{"name":"stdout","output_type":"stream","text":["Epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.56it/s, loss=0.0816]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.72it/s, accuracy=0.963]"]},{"name":"stdout","output_type":"stream","text":["Epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.59it/s, loss=0.0645]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.74it/s, accuracy=0.938]"]},{"name":"stdout","output_type":"stream","text":["Epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.57it/s, loss=0.0474]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.75it/s, accuracy=0.963]"]},{"name":"stdout","output_type":"stream","text":["Epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.62it/s, loss=0.0277]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.88it/s, accuracy=0.932]"]},{"name":"stdout","output_type":"stream","text":["Epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.72it/s, loss=0.0224]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.70it/s, accuracy=0.921]"]},{"name":"stdout","output_type":"stream","text":["Epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.70it/s, loss=0.0481]\n","Validation: 100%|██████████| 100/100 [00:15<00:00,  6.65it/s, accuracy=0.955]"]},{"name":"stdout","output_type":"stream","text":["Epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.10it/s, loss=0.0437]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.80it/s, accuracy=0.962]"]},{"name":"stdout","output_type":"stream","text":["Epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.59it/s, loss=0.0471]\n","Validation: 100%|██████████| 100/100 [00:15<00:00,  6.62it/s, accuracy=0.965]"]},{"name":"stdout","output_type":"stream","text":["Epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.61it/s, loss=0.0209]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.77it/s, accuracy=0.957]"]},{"name":"stdout","output_type":"stream","text":["Epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.60it/s, loss=0.0135]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.77it/s, accuracy=0.943]"]},{"name":"stdout","output_type":"stream","text":["Epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.69it/s, loss=0.0103]\n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.79it/s, accuracy=0.916]"]},{"name":"stdout","output_type":"stream","text":["Epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Training: 100%|██████████| 10/10 [00:02<00:00,  4.60it/s, loss=0.015] \n","Validation: 100%|██████████| 100/100 [00:14<00:00,  6.82it/s, accuracy=0.935]\n"]}],"source":["best_final_accuracy = 0.0\n","final_state = new_model.state_dict()\n","for epoch in range(n_epochs):\n","    print(f\"Epoch {epoch}\")\n","    average_loss = training_epoch(new_model, test_loader, test_optimizer)\n","    final_accuracy, precision, recall, f1 = evaluate(\n","        new_model, final_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n","    )\n","    if final_accuracy > best_final_accuracy:\n","        best_final_accuracy = final_accuracy\n","        print(\"new best model!\")\n","        final_state = copy.deepcopy(new_model.state_dict())\n","        torch.save(final_state, \"final_model.pth\")\n","    train_scheduler.step()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model.load_state_dict(final_state)\n","accuracy = evaluate(new_model, final_loader, device=DEVICE)\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T12:36:37.419630Z","iopub.status.busy":"2024-02-19T12:36:37.419218Z","iopub.status.idle":"2024-02-19T12:36:37.425445Z","shell.execute_reply":"2024-02-19T12:36:37.424406Z","shell.execute_reply.started":"2024-02-19T12:36:37.419598Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average accuracy: 96.71 %\n","Precision: 96.81 %\n","Recall: 96.71 %\n","F1-score: 96.69 %\n"]}],"source":["print(f\"Average accuracy: {100 * accuracy[0]:.2f} %\")\n","print(f\"Precision: {100 * accuracy[1]:.2f} %\")\n","print(f\"Recall: {100 * accuracy[2]:.2f} %\")\n","print(f\"F1-score: {100 * accuracy[3]:.2f} %\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model.laod_state_dict(final_state)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4462021,"sourceId":7653656,"sourceType":"datasetVersion"},{"datasetId":4423683,"sourceId":7599371,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
